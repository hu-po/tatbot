# Todo

Roughly sorted by priority

- rpi1 as dns server, viz network chatter
- The stroke MCP tool calls the batch creation MCP tool using file paths to coordinate. Other one waits until file is available to continue. Mcp tool calls MCP tool. Viz tool is also called, pulling up the latest viz on the rpi screen.
- Alignment and calib should be optional add ons to any recording session. 
- Add origin as alignment points, undergrid with sticking up points to get alignment
- GUI used by webui agent
- Use the white amcrest to observe the 3d printer.
- Plug 3d printer into other battery
- async policy server/client on https://github.com/hu-po/lerobot/blob/main/docs/source/async.mdx
- JAX on ojo via jetson-containers https://github.com/dusty-nv/jetson-containers/tree/master/packages/ml/jax
- red sharpie cross with laser line leveler
- mcp server for strokebatch job
- write local, sync later for robot recordings to save trossen-ai compute
- affine heat method for design wrapping on skin mesh
- ee calibration using square
- replace JAX ik with Nvidia warp ik
- build the new hardware and switch to the 3d print workflow and single arm queues and behavior trees and base mounted ink palettes
- Lerobot tatbot can take any number/subset of these three abstractions: ip_cameras, wxai_arms, rs_cameras
- colmap/Xm2 use AprilTag to construct scene graph
- Realsense incorporated with scissor lift pen adaptable, circular section of skin pressed softly on with barrier for sanitation
- use the jaws for scissor lift for height on the needle for depth. removes the need for batch ik, saving computation, giving the perfect angle and solves the safety problem too, since the strength can be tuned 
- tatbot logo with https://youtube.com/@mrupsidedownshorts
- use VLM call with horizontal lines to ask if tips are close or not
- calculate multiple points along the needle offset normal vector for every pose, this can be done in a batch before each episode. then the user has full control in realtime where they can move up and down that needle offset normal vector. the red safety button instantly sets the next pose to the most retracted point in the normal vector
- Points in image space used to get points in mesh using affine map. Points on ply/mesh are used to sample dense points using geodesic. Geodesic is used to create evenly spaced batch of vector offset 6d ee poses, with retraction and penetration vectors calculated effectively per position.
Viser gizmo controls design position, ply is saved per episode, mapping is done relative to a red sharpie cross drawn on
- Needle offset as part of stroke information so it can be updated in real time with human feedback
- Plan is the behavior tree abstraction
- Inks in the conditioning dataset
- StrokeQueue where you can push in StrokeLists and pause then push in a StrokeList generated from calibration, Display StrokeQueue on Vizer UI and have pause, play, delete from queue, etc. 
- Randomly sample strokes from a StrokeList, order can be random and you can do multiple epochs over the same tattoo. Cumulative with gradient rather than something you raster and complete once. 
- Batch ik on ojo per episode gives him a job and brings familiarity to the policy server abstraction, ik server 
- Simplify point resampling by using meter positions in svg
- crop the pointcloud and vgg output to the workspace of tatbot, it is quite small. this can be fed into the polyscope map workflow easier than polycam meshes.
- Red sharpie cross of specific lengths, used to calibrate mesh/ply
- use natural rhythm of the computation, weave sequence of scan, plan, act
- queue as a primitive for stroke execution, idle while waiting for queue
- editable behavior trees, use same functions as mcp
- batch ik every episode
- camera poses in lerobot dataset 
- pointclouds in lerobot dataset
- better svg path to stroke conversion
- audio text input for ook
- replicate playground in touchscreen
- calibrate camera extrinsics using conditioning images
- floating joint for apriltags in urdf
- floating joint for cameras in urdf
- gui buttons: loop path, loop time, pause
- vizer teleop in lerobot branch
- bimanual using ik collision
- three color pattern with prompted needle switch
- initialize gsplat with pointcloud
- iterative apriltag tracking to determine camera extrinsics
- increase ip camera resolution for better skin reconstruction
- rpi2 screen is on tatbot tower, 2 screens, put sound bar screen on top and non sound screen underneath connected to trossen.
- apriltags on back of robot in view of cameras
- isaacsim (https://www.youtube.com/live/z7KdHGkUTNE)
- compare fake skin and real skin calibration pattern
- squeeze bottle reveal ASMR
- random start spawn for design and inkcap for domain randomization in episode recording
- train splats on lerobot style data
- crop wrist pointcloud using cone from left hand, combine with cropped head pointcloud for skin mesh
- swiftsketch pattern
- etymology section in paper
- tatbot website
- host policy on replicate
- policy switching and composition into longer behaviors
- use ik solver for extrinsic camera calibration using apriltags
- rust apriltag rtsp synced image and video mcp server
- rcam runs on raspberry pis, provides synced camera images and apriltag poses. meerkat runs lerobot controlling arms and realsenses. ojo runs policy server, skin reconstruction.
- VR teleop using pyroki ik
- inkdip as policy
- wrist camera orbiting movement for optimal skin reconstruction